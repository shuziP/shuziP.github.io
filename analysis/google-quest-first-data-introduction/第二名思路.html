<!DOCTYPE html>





<html class="theme-next mist" lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="generator" content="Hexo 3.9.0">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    search: {
      root: '/',
      path: ''
    },
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copiar',
      copy_success: 'Copiado',
      copy_failure: 'Copiar falló'
    }
  };
</script>

  <meta name="description" content="Two BERTs are better than one (2nd place solution) 原文地址：https://www.kaggle.com/c/google-quest-challenge/discussion/129978 感谢赞助商和kaggle举办了如此有趣而富有挑战性的比赛!我们的工作是组织了一个牛逼的团队努力和冲刺排行榜，在非常短的两周时间内，我们每天都取得了进步。为什">
<meta property="og:type" content="website">
<meta property="og:title" content="谷歌语句对匹配第二名思路整理">
<meta property="og:url" content="https://github.com/shuziP/shuzip.github.io.git/analysis/google-quest-first-data-introduction/第二名思路.html">
<meta property="og:site_name" content="shuzip">
<meta property="og:description" content="Two BERTs are better than one (2nd place solution) 原文地址：https://www.kaggle.com/c/google-quest-challenge/discussion/129978 感谢赞助商和kaggle举办了如此有趣而富有挑战性的比赛!我们的工作是组织了一个牛逼的团队努力和冲刺排行榜，在非常短的两周时间内，我们每天都取得了进步。为什">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2020-03-07T17:20:07.604Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="谷歌语句对匹配第二名思路整理">
<meta name="twitter:description" content="Two BERTs are better than one (2nd place solution) 原文地址：https://www.kaggle.com/c/google-quest-challenge/discussion/129978 感谢赞助商和kaggle举办了如此有趣而富有挑战性的比赛!我们的工作是组织了一个牛逼的团队努力和冲刺排行榜，在非常短的两周时间内，我们每天都取得了进步。为什">
  <link rel="canonical" href="https://github.com/shuziP/shuzip.github.io.git/analysis/google-quest-first-data-introduction/第二名思路">


<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>谷歌语句对匹配第二名思路整理 | shuzip</title>
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">shuzip</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">blog</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Cambiar a barra de navegación">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
    <ul id="menu" class="menu">
        
        
        
          
          <li class="menu-item menu-item-home">

    <a href="/HOME/" rel="section">HOME</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-代码code">

    <a href="/code/" rel="section">代码code</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-音乐music">

    <a href="/music/" rel="section">音乐music</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-数据分析analysis menu-item-active">

    <a href="/analysis/" rel="section">数据分析analysis</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-内容分类categories">

    <a href="/categories/" rel="section">内容分类categories</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    <a href="/about/" rel="section">ABOUT</a>

  </li>
    </ul>
    

    
    
      
      
    
      
      
    
      
      
    
      
      
    
      
      
    
      
      
    
    

  

</nav>

</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    
    
    
    <div class="post-block page">
      <header class="post-header">

<h1 class="post-title" itemprop="name headline">谷歌语句对匹配第二名思路整理

</h1>

<div class="post-meta">
  
  <ul class="breadcrumb">
      
      
        
          
            
          
          
            <li><a href="/analysis/">ANALYSIS</a></li>
          
        
      
    
      
      
        
          
            
          
          
            <li><a href="/analysis/google-quest-first-data-introduction/">GOOGLE-QUEST-FIRST-DATA-INTRODUCTION</a></li>
          
        
      
    
      
      
        
          
            
          
          
            <li>第二名思路</li>
          
        
      
    
  </ul>

</div>

</header>

      
      
      
      <div class="post-body">
        
          <p>Two BERTs are better than one (2nd place solution)</p>
<p>原文地址：<a href="https://www.kaggle.com/c/google-quest-challenge/discussion/129978">https://www.kaggle.com/c/google-quest-challenge/discussion/129978</a></p>
<p>感谢赞助商和kaggle举办了如此有趣而富有挑战性的比赛!我们的工作是组织了一个牛逼的团队努力和冲刺排行榜，在非常短的两周时间内，我们每天都取得了进步。<br>为什么只用两个星期吗?因为我们中的一些人刚刚完成了TF2 QA竞赛，并决定重用在那里获得的所有NLP知识。感谢所有队友@christofhenkel @cpmpml @philippsinger @dott1718 @maxjeblick.</p>
<p>请也给他们投票，我们抽签决定谁公开解决方案，每个人都平等地贡献。</p>
<p>我们唯一遗憾的是，最终的分数太过依赖于questiontypespelling column，它在训练数据中只有11个非零的目标值。Late submission的实验表明，我们可以很容易地提高或降低我们的最终排名，只要稍微调整一下我们如何处理这一列。</p>
<h2 id="Brief-Summary"><a href="#Brief-Summary" class="headerlink" title="Brief Summary"></a>Brief Summary</h2><p>Like most teams, we used pretrained models from huggingface implemented in pytorch. Our final blend consists of 5 transformer models, that have several differences to push diversity. However, they all have in common to use 2 separate inputs of up to 512 tokens length representing questions respectively answers. These 2 inputs go either through the same transformer or through 2 separate transformers. We changed the targets to an ordinal representation (setting &gt;target to 1) resulting in 170 target columns with each original column having n-unique target columns. Predictions were then generated by calculating the expected value.</p>
<p>Most models were trained with differential learning rate, where the transformer gets a lr of 3-e5 and the model head(s) a lr of 0.005 and used a cosine schedule for training 3 epochs including warmup over one epoch. Optimizer were either AdamW or RAdam with weight decay of 0.01 using an effective batchsize of 8 (gradient accumulation).</p>
<p>Dual roberta-base:</p>
<p>double roberta-base<br>added question title as input to answer-transformer<br>individual head for each target<br>mean of last layer output<br>Dual roberta-base:</p>
<p>double roberta-base<br>added question title as input to answer-transformer<br>individual head for each target<br>mean of last layer output<br>Siamese roberta-base with softmax layer weight:</p>
<p>double roberta-base<br>added question title as input to answer-transformer<br>individual head for each target<br>mean of last layer output<br>Dual roberta-large:</p>
<p>only use 256 tokens for question / answer<br>double roberta-large<br>only fits in memory with batchsize 1 and fp16<br>Dual xlnet:</p>
<p>same as dual roberta-base but with xlnet-base backbone<br>We used a simple average of probabiity predictions to ensemble our models.<br>Longer Summary<br>Binary Encoded Targets<br>Given the metric is rank-based, and given targets are not binary, it seemed important to be able to predict values that are neither 0 or 1 correctly. We tried mse loss and other variants but results were not satisfactory. We then decided to use binary cross-entropy with binary targets. The first try was to use on hot encoding of targets, given that targets have a small number of distinct values. This wasn’t satisfactory either, because this representation loses the ordering of values.<br>We ended up using an encoding of the form (t &gt; v) for all v values of target t, except last value. For instance, if a target t has unique values [0, ⅓, ⅔, 1] then we would get 3 binary targets: t &gt; 0, t&gt; ⅓, and t &gt; ⅔. Assuming we get perfect probability predictions p(0), p(⅓ ), and p(⅔) for the binary targets, we can compute predictions for each value of the original target as:<br>t(0)= 1 - p(0) t(⅓)= p(0) - p(⅓) t(⅔)= p(⅓) - p(⅔) t(1)= p(⅔) - 0<br>And the original target value as<br>t = 0 * t(0) + ⅓ * t(⅓) + ⅔ * t(⅔) + 1*t(1)<br>We keep that computation with the actual predictions p(0), p(⅓ ), and p(⅔) for the binary targets.<br>When the values are evenly spaced, as in this example, then the formula simplifies into:<br>t = mean(p(0), p(⅓ ), p(⅔))<br>If we assume that what matters is only the order of values, then we can stick to this simplified form.<br>We used the simplified form throughout the competition as it was simpler to code, and faster. In our final two selected subs we reverted to the exact computation because it was better on both cv and public LB, but this didn’t change private LB significantly (0.0004 difference).</p>
<p>Validation scheme<br>Similar to most teams, we use a 5-fold GroupKFold on question body for fitting our models and evaluation. After a bunch of experiments we saw though, that this is not sufficient mainly due to the following aspects:</p>
<p>Test data is different to training data in the sense that it only has one question-answer pair sampled out of a group of questions in train data. There can be stark noise for labels of the same question, which is why this needs to be addressed robustly.<br>There are a few columns with very rare events and also a lot of noise within those rare events. The prime example is spelling which has a huge impact on CV and LB, but can completely blind your view when trying to judge the overall strength of your model.<br>That is why we settled after some time on the following full validation scheme:</p>
<p>Use 5-fold GroupKFold on question body<br>For each validation fold, sample 100 times randomly a single question-answer pair out of multiple questions.<br>Calculate the median score across these 100 samples and report.<br>Ignore spelling column.<br>Final CV is a mean of 5 folds.<br>This setup also allowed us to properly test any type of postprocessing in a realistic manner as described next.<br>Postprocessing<br>Even though we had really strong models, post-processing was very important to us and we spent significant time on it to find a robust way that we can trust. It is based on threshold clipping.<br>For each target column, we separately attempt to find optimal thresholds from both sides (starting from lowest predictions and highest predictions) based on which we clip the data. So let’s assume our predictions look like x=[0.01, 0.015, 0.02, 0.03, 0.04] and our optimal thresholds are coefs=[0.016, 0.029] then we would clip the data with np.clip(x, coefs[0], coefs[1]) leading to x=[0.016, 0.016, 0.02, 0.029, 0.029] effectively generating ties at the edges.</p>
<p>The CV setup from above gave us a perfect way to fully validate any of our approaches by simply generating the thresholds on training folds, and applying them on truncated samples of the validation folds. For final PP, we get the thresholds on full oof and apply them on the test set.<br>In a nutshell, our routine looks like the following:</p>
<p>Sample 1000 times single question-answer pairs from multiple questions<br>Generate thresholds that optimize the median score of all 1000 samples<br>We tested quite a few different strategies, but this one was the most robust one we found and we are quite happy with it. Only for spelling, it was still a bit shaky, which is why our two final subs just differ in how we handle spelling column, one uses the calculated thresholds, and one hard-sets the 6 highest predictions in private LB to 1 and rest to 0 which is based on experiments on samples.<br>Unfortunately, if we would have post-processed all columns except spelling and would have kept spelling as is, we would have reached 0.432 on private LB as apparently spelling is very differently distributed on private. No CV experiment would have let us make this decision though. It would have been so much better though to not include this column into the competition.</p>
<p>Architectures and training models<br>Similar to other recent competitions at first it was quite difficult to beat public kernels, which we normally see as a kind of baseline. All “normal” tricks that worked in past computer vision or other NLP competitions (e.g. concat of Max and Mean pooling) did not improve cv. Also using a sliding window approach to capture more text did not work.<br>We saw a first big improvement when using 2 transformers instead of one (+0.01), but still, any slightly more complex architectures lead to a worse result. That changed when we tried to freeze the transformers and only train the model head for 1 epoch, before fine-tuning. With this approach, we were able to try more fancy things and that is also how we finally came to the two main architectures.<br>We further improved than this 2 step approach by using different learning rates for transformer and head, together with a warm up schedule, which enabled us to get rid of the freezing step in general. We illustrate the two main architectures in the following figure (For the sake of simplicity we show the architecture for the original 30 targets. It was adapted to work with the binarized targets.).</p>
<p>Dual Transformer:<br>The upper architecture shows the dual transformer model, a combo model where one transformer handles the question text, while a second transformer handles the answer text. the output of the last layer is then averaged over the 512 tokens and both resulting tensors are concatenated. The resulting representation is then fed into 30 little 2 fully connected layers which result in the target predictions. 30 little heads enable each target to have its own head and gain individuality.</p>
<p>Siamese Transformer with soft weighted layers:<br>It is inspired by the Elmo paper, where the final embedding representation is a weighted average of all LSTM layers. We use the output of every layer of a single transformer model in which we put 512 question and 512 answer tokens. For roberta-base that will give us twelve 512x768 tensors (for roberta large it would be 24 512x1024 tensors). We then average over the 512 tokens for each layer which results in twelve 768 representations. We then take a weighted sum of these 12 representations (where the weights for adding the representations are trainable!). This results in a 768 representation. The weighted average of all layer outputs enables to capture low level features in the final representation which was quite important for some answer related targets. Finally, we add a single prediction head for getting our targets.</p>
<p>Our final ensemble contains 5 models which belong to the one or the other architecture, and only differ in used pretrained backbone.<br>We ended up with</p>
<p>2x dual roberta-base<br>dual roberta-large (2x 256 tokens)<br>dual xnet-base<br>siamese roberta-large with weighted averaged layers<br>as this combination had the best cv score while fitting in the 2h kernel runtime requirement.<br>We even trained one dual roberta-large model which on a V100 can only be trained when using a batch size of 1 and fp16. and was our best single model. Although this model could not fit into the ensemble due to runtime reasons, the promising cv results let us to a daring experiment: reducing the number of tokens used. There we saw something quite surprising. We could reduce the number of tokens to 256 for question as well as for answer without losing much quality.</p>
<p>Most models were trained with differential learning rate, where the transformer gets a lr of 3-e5 and the model head(s) a lr of 0.005 and used a cosine schedule for training 3 epochs including warmup over one epoch. Optimizer were either AdamW or RAdam with weight decay of 0.01 using an effective batchsize of 8 (gradient accumulation).</p>
<p>Blending<br>Our submission includes an equally weighted blend between all of above mentioned 5 models (leading to 25 test predictions with 5-fold). The blend is conducted on raw expected values calculated as described above. We experimented quite a bit with ranked blending as it seemed natural, but results were always worse.<br>Our final blend is both our best one on CV, public LB and private LB meaning that we had a robust CV setup in the end and our selection was solid.</p>
<p>Wrapping things up and putting into kernel<br>Training was conducted offline and inference in kernel. Our final runtime was close to two hours and we had to spend some efforts to squeeze the 5 models in. All our models are implemented in Pytorch using the amazing Huggingface library. Fitting was done either locally or on cloud providers.</p>
<p>Thanks for reading.</p>

        
      </div>
      
      
      
    </div>
    
  <ul class="breadcrumb">
      
      
        
          
            
          
          
            <li><a href="/analysis/">ANALYSIS</a></li>
          
        
      
    
      
      
        
          
            
          
          
            <li><a href="/analysis/google-quest-first-data-introduction/">GOOGLE-QUEST-FIRST-DATA-INTRODUCTION</a></li>
          
        
      
    
      
      
        
          
            
          
          
            <li>第二名思路</li>
          
        
      
    
  </ul>

    
    
    
  </div>


          </div>
          


        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Tabla de contenidos
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Inicio
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">shuzip</p>
  <div class="site-description motion-element" itemprop="description"></div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives">
        
          <span class="site-state-item-count">15</span>
          <span class="site-state-item-name">entradas</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
          
        
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">categorías</span>
        </a>
      </div>
    
  </nav>



        </div>
      </div>
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Brief-Summary"><span class="nav-number">1.</span> <span class="nav-text">Brief Summary</span></a></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">shuzip</span>
</div>

        








        
      </div>
    </footer>
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
      </div>

    

  </div>

  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  <script src="/js/utils.js?v=7.3.0"></script>

  
  <script src="/js/schemes/muse.js?v=7.3.0"></script>



  
    <script src="/js/scrollspy.js?v=7.3.0"></script>
<script src="/js/post-details.js?v=7.3.0"></script>

  


  <script src="/js/next-boot.js?v=7.3.0"></script>

  

  

  


  




























<script>
if ($('body').find('div.pdf').length) {
  $.ajax({
    type: 'GET',
    url: '//cdn.jsdelivr.net/npm/pdfobject@2/pdfobject.min.js',
    dataType: 'script',
    cache: true,
    success: function() {
      $('body').find('div.pdf').each(function(i, o) {
        PDFObject.embed($(o).attr('target'), $(o), {
          pdfOpenParams: {
            navpanes: 0,
            toolbar: 0,
            statusbar: 0,
            pagemode: 'thumbs',
            view: 'FitH'
          },
          PDFJS_URL: '/lib/pdf/web/viewer.html',
          height: $(o).attr('height') || '500px'
        });
      });
    },
  });
}
</script>






</body>
</html>
