<!DOCTYPE html>





<html class="theme-next mist" lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="generator" content="Hexo 3.9.0">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    search: {
      root: '/',
      path: ''
    },
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Kopieren',
      copy_success: 'Kopiert',
      copy_failure: 'Kopieren fehlgeschlagen'
    }
  };
</script>

  <meta name="description" content="Android原文链接：https://pytorch.org/mobile/android/ QUICKSTART WITH A HELLOWORLD EXAMPLEHelloWorld is a simple image classification application that demonstrates how to use PyTorch Android API. This appli">
<meta property="og:type" content="website">
<meta property="og:title" content="shuzip">
<meta property="og:url" content="https://github.com/shuziP/shuzip.github.io.git/essays/[pytorch翻译]Android.html">
<meta property="og:site_name" content="shuzip">
<meta property="og:description" content="Android原文链接：https://pytorch.org/mobile/android/ QUICKSTART WITH A HELLOWORLD EXAMPLEHelloWorld is a simple image classification application that demonstrates how to use PyTorch Android API. This appli">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2020-02-12T14:28:08.473Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="shuzip">
<meta name="twitter:description" content="Android原文链接：https://pytorch.org/mobile/android/ QUICKSTART WITH A HELLOWORLD EXAMPLEHelloWorld is a simple image classification application that demonstrates how to use PyTorch Android API. This appli">
  <link rel="canonical" href="https://github.com/shuziP/shuzip.github.io.git/essays/[pytorch翻译]Android">


<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title> | shuzip</title>
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">shuzip</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">blog</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Navigationsleiste an/ausschalten">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
    <ul id="menu" class="menu">
        
        
        
          
          <li class="menu-item menu-item-home">

    <a href="/HOME/" rel="section">HOME</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-代码code">

    <a href="https://github.com/shuziP" rel="section">代码code</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-音乐music">

    <a href="/music/" rel="section">音乐music</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-文章essays">

    <a href="/" rel="section">文章essays</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-数据分析analysis">

    <a href="/analysis/" rel="section">数据分析analysis</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    <a href="/about/" rel="section">ABOUT</a>

  </li>
    </ul>
    

    
    
      
      
    
      
      
    
      
      
    
      
      
    
      
      
    
      
      
    
    

  

</nav>

</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    
    
    
    <div class="post-block page">
      <header class="post-header">

<h1 class="post-title" itemprop="name headline">

</h1>

<div class="post-meta">
  

</div>

</header>

      
      
      
      <div class="post-body">
        
          <h1 id="Android"><a href="#Android" class="headerlink" title="Android"></a>Android</h1><p>原文链接：<a href="https://pytorch.org/mobile/android/" target="_blank" rel="noopener">https://pytorch.org/mobile/android/</a></p>
<h2 id="QUICKSTART-WITH-A-HELLOWORLD-EXAMPLE"><a href="#QUICKSTART-WITH-A-HELLOWORLD-EXAMPLE" class="headerlink" title="QUICKSTART WITH A HELLOWORLD EXAMPLE"></a>QUICKSTART WITH A HELLOWORLD EXAMPLE</h2><p><a href="https://github.com/pytorch/android-demo-app/tree/master/HelloWorldApp">HelloWorld</a> is a simple image classification application that demonstrates how to use PyTorch Android API. This application runs TorchScript serialized TorchVision pretrained resnet18 model on static image which is packaged inside the app as android asset.</p>
<h4 id="1-Model-Preparation"><a href="#1-Model-Preparation" class="headerlink" title="1. Model Preparation"></a>1. Model Preparation</h4><p>Let’s start with model preparation. If you are familiar with PyTorch, you probably should already know how to train and save your model. In case you don’t, we are going to use a pre-trained image classification model (<a href="https://pytorch.org/hub/pytorch_vision_resnet/" target="_blank" rel="noopener">Resnet18</a>), which is packaged in <a href="https://pytorch.org/docs/stable/torchvision/index.html" target="_blank" rel="noopener">TorchVision</a>. To install it, run the command below:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torchvision</span><br></pre></td></tr></table></figure>

<p>To serialize the model you can use python <a href="https://github.com/pytorch/android-demo-app/blob/master/HelloWorldApp/trace_model.py">script</a> in the root folder of HelloWorld app:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line"></span><br><span class="line">model = torchvision.models.resnet18(pretrained=True)</span><br><span class="line">model.eval()</span><br><span class="line">example = torch.rand(1, 3, 224, 224)</span><br><span class="line">traced_script_module = torch.jit.trace(model, example)</span><br><span class="line">traced_script_module.save(&quot;app/src/main/assets/model.pt&quot;)</span><br></pre></td></tr></table></figure>

<p>If everything works well, we should have our model - <code>model.pt</code> generated in the assets folder of android application. That will be packaged inside android application as <code>asset</code> and can be used on the device.</p>
<p>More details about TorchScript you can find in <a href="https://pytorch.org/docs/stable/jit.html" target="_blank" rel="noopener">tutorials on pytorch.org</a></p>
<h4 id="2-Cloning-from-github"><a href="#2-Cloning-from-github" class="headerlink" title="2. Cloning from github"></a>2. Cloning from github</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/pytorch/android-demo-app.git</span><br><span class="line">cd HelloWorldApp</span><br></pre></td></tr></table></figure>

<p>If <a href="https://developer.android.com/studio/index.html#command-tools" target="_blank" rel="noopener">Android SDK</a> and <a href="https://developer.android.com/ndk/downloads" target="_blank" rel="noopener">Android NDK</a> are already installed you can install this application to the connected android device or emulator with:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./gradlew installDebug</span><br></pre></td></tr></table></figure>

<p>We recommend you to open this project in <a href="https://developer.android.com/studio" target="_blank" rel="noopener">Android Studio 3.5.1+</a>. At the moment PyTorch Android and demo applications use <a href="https://developer.android.com/studio/releases/gradle-plugin#3-5-0" target="_blank" rel="noopener">android gradle plugin of version 3.5.0</a>, which is supported only by Android Studio version 3.5.1 and higher. Using Android Studio you will be able to install Android NDK and Android SDK with Android Studio UI.</p>
<h4 id="3-Gradle-dependencies"><a href="#3-Gradle-dependencies" class="headerlink" title="3. Gradle dependencies"></a>3. Gradle dependencies</h4><p>Pytorch android is added to the HelloWorld as <a href="https://github.com/pytorch/android-demo-app/blob/master/HelloWorldApp/app/build.gradle#L28-L29">gradle dependencies</a> in build.gradle:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">repositories &#123;</span><br><span class="line">    jcenter()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">dependencies &#123;</span><br><span class="line">    implementation &apos;org.pytorch:pytorch_android:1.4.0&apos;</span><br><span class="line">    implementation &apos;org.pytorch:pytorch_android_torchvision:1.4.0&apos;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Where <code>org.pytorch:pytorch_android</code> is the main dependency with PyTorch Android API, including libtorch native library for all 4 android abis (armeabi-v7a, arm64-v8a, x86, x86_64). Further in this doc you can find how to rebuild it only for specific list of android abis.</p>
<p><code>org.pytorch:pytorch_android_torchvision</code> - additional library with utility functions for converting <code>android.media.Image</code> and <code>android.graphics.Bitmap</code> to tensors.</p>
<h4 id="4-Reading-image-from-Android-Asset"><a href="#4-Reading-image-from-Android-Asset" class="headerlink" title="4. Reading image from Android Asset"></a>4. Reading image from Android Asset</h4><p>All the logic happens in <a href="https://github.com/pytorch/android-demo-app/blob/master/HelloWorldApp/app/src/main/java/org/pytorch/helloworld/MainActivity.java#L31-L69"><code>org.pytorch.helloworld.MainActivity</code></a>. As a first step we read <code>image.jpg</code> to <code>android.graphics.Bitmap</code> using the standard Android API.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Bitmap bitmap = BitmapFactory.decodeStream(getAssets().open(&quot;image.jpg&quot;));</span><br></pre></td></tr></table></figure>

<h4 id="5-Loading-TorchScript-Module"><a href="#5-Loading-TorchScript-Module" class="headerlink" title="5. Loading TorchScript Module"></a>5. Loading TorchScript Module</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Module module = Module.load(assetFilePath(this, &quot;model.pt&quot;));</span><br></pre></td></tr></table></figure>

<p><code>org.pytorch.Module</code> represents <code>torch::jit::script::Module</code> that can be loaded with <code>load</code> method specifying file path to the serialized to file model.</p>
<h4 id="6-Preparing-Input"><a href="#6-Preparing-Input" class="headerlink" title="6. Preparing Input"></a>6. Preparing Input</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Tensor inputTensor = TensorImageUtils.bitmapToFloat32Tensor(bitmap,</span><br><span class="line">    TensorImageUtils.TORCHVISION_NORM_MEAN_RGB, TensorImageUtils.TORCHVISION_NORM_STD_RGB);</span><br></pre></td></tr></table></figure>

<p><code>org.pytorch.torchvision.TensorImageUtils</code> is part of <code>org.pytorch:pytorch_android_torchvision</code> library. The <code>TensorImageUtils#bitmapToFloat32Tensor</code> method creates tensors in the <a href="https://pytorch.org/docs/stable/torchvision/models.html" target="_blank" rel="noopener">torchvision format</a> using <code>android.graphics.Bitmap</code> as a source.</p>
<blockquote>
<p>All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of <code>[0, 1]</code> and then normalized using <code>mean = [0.485, 0.456, 0.406]</code> and <code>std = [0.229, 0.224, 0.225]</code></p>
</blockquote>
<p><code>inputTensor</code>’s shape is <code>1x3xHxW</code>, where <code>H</code> and <code>W</code> are bitmap height and width appropriately.</p>
<h4 id="7-Run-Inference"><a href="#7-Run-Inference" class="headerlink" title="7. Run Inference"></a>7. Run Inference</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Tensor outputTensor = module.forward(IValue.from(inputTensor)).toTensor();</span><br><span class="line">float[] scores = outputTensor.getDataAsFloatArray();</span><br></pre></td></tr></table></figure>

<p><code>org.pytorch.Module.forward</code> method runs loaded module’s <code>forward</code> method and gets result as <code>org.pytorch.Tensor</code> outputTensor with shape <code>1x1000</code>.</p>
<h4 id="8-Processing-results"><a href="#8-Processing-results" class="headerlink" title="8. Processing results"></a>8. Processing results</h4><p>Its content is retrieved using <code>org.pytorch.Tensor.getDataAsFloatArray()</code> method that returns java array of floats with scores for every image net class.</p>
<p>After that we just find index with maximum score and retrieve predicted class name from <code>ImageNetClasses.IMAGENET_CLASSES</code> array that contains all ImageNet classes.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">float maxScore = -Float.MAX_VALUE;</span><br><span class="line">int maxScoreIdx = -1;</span><br><span class="line">for (int i = 0; i &lt; scores.length; i++) &#123;</span><br><span class="line">  if (scores[i] &gt; maxScore) &#123;</span><br><span class="line">    maxScore = scores[i];</span><br><span class="line">    maxScoreIdx = i;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">String className = ImageNetClasses.IMAGENET_CLASSES[maxScoreIdx];</span><br></pre></td></tr></table></figure>

<p>In the following sections you can find detailed explanations of PyTorch Android API, code walk through for a bigger <a href="https://github.com/pytorch/android-demo-app/tree/master/PyTorchDemoApp">demo application</a>, implementation details of the API, how to customize and build it from source.</p>
<h2 id="PYTORCH-DEMO-APPLICATION"><a href="#PYTORCH-DEMO-APPLICATION" class="headerlink" title="PYTORCH DEMO APPLICATION"></a>PYTORCH DEMO APPLICATION</h2><p>We have also created another more complex PyTorch Android demo application that does image classification from camera output and text classification in the <a href="https://github.com/pytorch/android-demo-app/tree/master/PyTorchDemoApp">same github repo</a>.</p>
<p>To get device camera output it uses <a href="https://developer.android.com/training/camerax" target="_blank" rel="noopener">Android CameraX API</a>. All the logic that works with CameraX is separated to <a href="https://github.com/pytorch/android-demo-app/blob/master/PyTorchDemoApp/app/src/main/java/org/pytorch/demo/vision/AbstractCameraXActivity.java"><code>org.pytorch.demo.vision.AbstractCameraXActivity</code></a> class.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">void setupCameraX() &#123;</span><br><span class="line">    final PreviewConfig previewConfig = new PreviewConfig.Builder().build();</span><br><span class="line">    final Preview preview = new Preview(previewConfig);</span><br><span class="line">    preview.setOnPreviewOutputUpdateListener(output -&gt; mTextureView.setSurfaceTexture(output.getSurfaceTexture()));</span><br><span class="line"></span><br><span class="line">    final ImageAnalysisConfig imageAnalysisConfig =</span><br><span class="line">        new ImageAnalysisConfig.Builder()</span><br><span class="line">            .setTargetResolution(new Size(224, 224))</span><br><span class="line">            .setCallbackHandler(mBackgroundHandler)</span><br><span class="line">            .setImageReaderMode(ImageAnalysis.ImageReaderMode.ACQUIRE_LATEST_IMAGE)</span><br><span class="line">            .build();</span><br><span class="line">    final ImageAnalysis imageAnalysis = new ImageAnalysis(imageAnalysisConfig);</span><br><span class="line">    imageAnalysis.setAnalyzer(</span><br><span class="line">        (image, rotationDegrees) -&gt; &#123;</span><br><span class="line">          analyzeImage(image, rotationDegrees);</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">    CameraX.bindToLifecycle(this, preview, imageAnalysis);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  void analyzeImage(android.media.Image, int rotationDegrees)</span><br></pre></td></tr></table></figure>

<p>Where the <code>analyzeImage</code> method process the camera output, <code>android.media.Image</code>.</p>
<p>It uses the aforementioned <a href="https://github.com/pytorch/pytorch/blob/master/android/pytorch_android_torchvision/src/main/java/org/pytorch/torchvision/TensorImageUtils.java#L90"><code>TensorImageUtils.imageYUV420CenterCropToFloat32Tensor</code></a> method to convert <code>android.media.Image</code> in <code>YUV420</code> format to input tensor.</p>
<p>After getting predicted scores from the model it finds top K classes with the highest scores and shows on the UI.</p>
<h4 id="Language-Processing-Example"><a href="#Language-Processing-Example" class="headerlink" title="Language Processing Example"></a>Language Processing Example</h4><p>Another example is natural language processing, based on an LSTM model, trained on a reddit comments dataset. The logic happens in <a href="https://github.com/pytorch/android-demo-app/blob/master/PyTorchDemoApp/app/src/main/java/org/pytorch/demo/nlp/TextClassificationActivity.java"><code>TextClassificattionActivity</code></a>.</p>
<p>Result class names are packaged inside the TorchScript model and initialized just after initial module initialization. The module has a <code>get_classes</code> method that returns <code>List[str]</code>, which can be called using method <code>Module.runMethod(methodName)</code>:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mModule = Module.load(moduleFileAbsoluteFilePath);</span><br><span class="line">IValue getClassesOutput = mModule.runMethod(&quot;get_classes&quot;);</span><br></pre></td></tr></table></figure>

<p>The returned <code>IValue</code> can be converted to java array of <code>IValue</code> using <code>IValue.toList()</code> and processed to an array of strings using <code>IValue.toStr()</code>:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">IValue[] classesListIValue = getClassesOutput.toList();</span><br><span class="line">String[] moduleClasses = new String[classesListIValue.length];</span><br><span class="line">int i = 0;</span><br><span class="line">for (IValue iv : classesListIValue) &#123;</span><br><span class="line">  moduleClasses[i++] = iv.toStr();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Entered text is converted to java array of bytes with <code>UTF-8</code> encoding. <code>Tensor.fromBlobUnsigned</code> creates tensor of <code>dtype=uint8</code> from that array of bytes.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">byte[] bytes = text.getBytes(Charset.forName(&quot;UTF-8&quot;));</span><br><span class="line">final long[] shape = new long[]&#123;1, bytes.length&#125;;</span><br><span class="line">final Tensor inputTensor = Tensor.fromBlobUnsigned(bytes, shape);</span><br></pre></td></tr></table></figure>

<p>Running inference of the model is similar to previous examples:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Tensor outputTensor = mModule.forward(IValue.from(inputTensor)).toTensor()</span><br></pre></td></tr></table></figure>

<p>After that, the code processes the output, finding classes with the highest scores.</p>
<h2 id="BUILDING-PYTORCH-ANDROID-FROM-SOURCE"><a href="#BUILDING-PYTORCH-ANDROID-FROM-SOURCE" class="headerlink" title="BUILDING PYTORCH ANDROID FROM SOURCE"></a>BUILDING PYTORCH ANDROID FROM SOURCE</h2><p>In some cases you might want to use a local build of pytorch android, for example you may build custom libtorch binary with another set of operators or to make local changes.</p>
<p>For this you can use <code>./scripts/build_pytorch_android.sh</code> script.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/pytorch/pytorch.git</span><br><span class="line">cd pytorch</span><br><span class="line">sh ./scripts/build_pytorch_android.sh</span><br></pre></td></tr></table></figure>

<p>The workflow contains several steps:</p>
<p>\1. Build libtorch for android for all 4 android abis (armeabi-v7a, arm64-v8a, x86, x86_64)</p>
<p>\2. Create symbolic links to the results of those builds: <code>android/pytorch_android/src/main/jniLibs/${abi}</code> to the directory with output libraries <code>android/pytorch_android/src/main/cpp/libtorch_include/${abi}</code> to the directory with headers. These directories are used to build <code>libpytorch.so</code> library that will be loaded on android device.</p>
<p>\3. And finally run <code>gradle</code> in <code>android/pytorch_android</code> directory with task <code>assembleRelease</code></p>
<p>Script requires that Android SDK, Android NDK and gradle are installed. They are specified as environment variables:</p>
<p><code>ANDROID_HOME</code> - path to <a href="https://developer.android.com/studio/command-line/sdkmanager.html" target="_blank" rel="noopener">Android SDK</a></p>
<p><code>ANDROID_NDK</code> - path to <a href="https://developer.android.com/studio/projects/install-ndk" target="_blank" rel="noopener">Android NDK</a></p>
<p><code>GRADLE_HOME</code> - path to <a href="https://gradle.org/releases/" target="_blank" rel="noopener">gradle</a></p>
<p>After successful build you should see the result as aar file:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ find pytorch_android/build/ -type f -name *aar</span><br><span class="line">pytorch_android/build/outputs/aar/pytorch_android.aar</span><br><span class="line">pytorch_android_torchvision/build/outputs/aar/pytorch_android.aar</span><br><span class="line">libs/fbjni_local/build/outputs/aar/pytorch_android_fbjni.aar</span><br></pre></td></tr></table></figure>

<p>It can be used directly in android projects, as a gradle dependency:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">allprojects &#123;</span><br><span class="line">    repositories &#123;</span><br><span class="line">        flatDir &#123;</span><br><span class="line">            dirs &apos;libs&apos;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">android &#123;</span><br><span class="line">    ...</span><br><span class="line">    packagingOptions &#123;</span><br><span class="line">        pickFirst &quot;**/libfbjni.so&quot;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">dependencies &#123;</span><br><span class="line">    implementation(name:&apos;pytorch_android&apos;, ext:&apos;aar&apos;)</span><br><span class="line">    implementation(name:&apos;pytorch_android_torchvision&apos;, ext:&apos;aar&apos;)</span><br><span class="line">    implementation(name:&apos;pytorch_android_fbjni&apos;, ext:&apos;aar&apos;)</span><br><span class="line">    ...</span><br><span class="line">    implementation &apos;com.android.support:appcompat-v7:28.0.0&apos;</span><br><span class="line">    implementation &apos;com.facebook.soloader:nativeloader:0.8.0&apos;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>At the moment for the case of using aar files directly we need additional configuration due to packaging specific (<code>libfbjni.so</code> is packaged in both <code>pytorch_android_fbjni.aar</code> and <code>pytorch_android.aar</code>).</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">packagingOptions &#123;</span><br><span class="line">    pickFirst &quot;**/libfbjni.so&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Also we have to add all transitive dependencies of our aars. As <code>pytorch_android</code> depends on <code>com.android.support:appcompat-v7:28.0.0</code> and <code>com.facebook.soloader:nativeloader:0.8.0</code>, we need to add them. (In case of using maven dependencies they are added automatically from <code>pom.xml</code>).</p>
<h2 id="CUSTOM-BUILD"><a href="#CUSTOM-BUILD" class="headerlink" title="CUSTOM BUILD"></a>CUSTOM BUILD</h2><p>To reduce the size of binaries you can do custom build of PyTorch Android with only set of operators required by your model. This includes two steps: preparing the list of operators from your model, rebuilding pytorch android with specified list.</p>
<p>\1. Verify your PyTorch version is 1.4.0 or above. You can do that by checking the value of <code>torch.__version__</code>.</p>
<p>\2. Preparation of the list of operators</p>
<p>List of operators of your serialized torchscript model can be prepared in yaml format using python api function <code>torch.jit.export_opnames()</code>. To dump the operators in your model, say <code>MobileNetV2</code>, run the following lines of Python code:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Dump list of operators used by MobileNetV2:</span><br><span class="line">import torch, yaml</span><br><span class="line">model = torch.jit.load(&apos;MobileNetV2.pt&apos;)</span><br><span class="line">ops = torch.jit.export_opnames(model)</span><br><span class="line">with open(&apos;MobileNetV2.yaml&apos;, &apos;w&apos;) as output:</span><br><span class="line">    yaml.dump(ops, output)</span><br></pre></td></tr></table></figure>

<p>\3. Building PyTorch Android with prepared operators list.</p>
<p>To build PyTorch Android with the prepared yaml list of operators, specify it in the environment variable <code>SELECTED_OP_LIST</code>. Also in the arguments, specify which Android ABIs it should build; by default it builds all 4 Android ABIs.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Build PyTorch Android library customized for MobileNetV2:</span><br><span class="line">SELECTED_OP_LIST=MobileNetV2.yaml scripts/build_pytorch_android.sh arm64-v8a</span><br></pre></td></tr></table></figure>

<p>After successful build you can integrate the result aar files to your android gradle project, following the steps from previous section of this tutorial (Building PyTorch Android from Source).</p>
<h2 id="API-DOCS"><a href="#API-DOCS" class="headerlink" title="API DOCS"></a>API DOCS</h2><p>You can find more details about the PyTorch Android API in the <a href="https://pytorch.org/javadoc/" target="_blank" rel="noopener">Javadoc</a>.</p>

        
      </div>
      
      
      
    </div>
    

    
    
    
  </div>


          </div>
          


        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Inhaltsverzeichnis
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Übersicht
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">shuzip</p>
  <div class="site-description motion-element" itemprop="description"></div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives">
        
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">Artikel</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
        
        
          
        
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">schlagwörter</span>
        
      </div>
    
  </nav>



        </div>
      </div>
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Android"><span class="nav-number">1.</span> <span class="nav-text">Android</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#QUICKSTART-WITH-A-HELLOWORLD-EXAMPLE"><span class="nav-number">1.1.</span> <span class="nav-text">QUICKSTART WITH A HELLOWORLD EXAMPLE</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-Model-Preparation"><span class="nav-number">1.1.0.1.</span> <span class="nav-text">1. Model Preparation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-Cloning-from-github"><span class="nav-number">1.1.0.2.</span> <span class="nav-text">2. Cloning from github</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-Gradle-dependencies"><span class="nav-number">1.1.0.3.</span> <span class="nav-text">3. Gradle dependencies</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-Reading-image-from-Android-Asset"><span class="nav-number">1.1.0.4.</span> <span class="nav-text">4. Reading image from Android Asset</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-Loading-TorchScript-Module"><span class="nav-number">1.1.0.5.</span> <span class="nav-text">5. Loading TorchScript Module</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-Preparing-Input"><span class="nav-number">1.1.0.6.</span> <span class="nav-text">6. Preparing Input</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-Run-Inference"><span class="nav-number">1.1.0.7.</span> <span class="nav-text">7. Run Inference</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-Processing-results"><span class="nav-number">1.1.0.8.</span> <span class="nav-text">8. Processing results</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PYTORCH-DEMO-APPLICATION"><span class="nav-number">1.2.</span> <span class="nav-text">PYTORCH DEMO APPLICATION</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Language-Processing-Example"><span class="nav-number">1.2.0.1.</span> <span class="nav-text">Language Processing Example</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BUILDING-PYTORCH-ANDROID-FROM-SOURCE"><span class="nav-number">1.3.</span> <span class="nav-text">BUILDING PYTORCH ANDROID FROM SOURCE</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CUSTOM-BUILD"><span class="nav-number">1.4.</span> <span class="nav-text">CUSTOM BUILD</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#API-DOCS"><span class="nav-number">1.5.</span> <span class="nav-text">API DOCS</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">shuzip</span>
</div>

        








        
      </div>
    </footer>
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
      </div>

    

  </div>

  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  <script src="/js/utils.js?v=7.3.0"></script>

  
  <script src="/js/schemes/muse.js?v=7.3.0"></script>



  
    <script src="/js/scrollspy.js?v=7.3.0"></script>
<script src="/js/post-details.js?v=7.3.0"></script>

  


  <script src="/js/next-boot.js?v=7.3.0"></script>

  

  

  


  


































</body>
</html>
